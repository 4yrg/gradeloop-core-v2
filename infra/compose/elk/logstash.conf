input {
  beats {
    port => 5044
  }
  tcp {
    port => 5000
    codec => json
  }
}

filter {
  # GradeLoop services log to stdout in JSON format.
  # Filebeat captures these logs and puts the JSON string in the "message" field.
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "log"
    }

    if [log][service_name] {
      # Extract mandatory schema fields for top-level indexing
      mutate {
        add_field => { "service_name" => "%{[log][service_name]}" }
        add_field => { "trace_id" => "%{[log][trace_id]}" }
        add_field => { "level" => "%{[log][level]}" }
        add_field => { "msg" => "%{[log][msg]}" }
      }

      # Parse the application timestamp to synchronize with @timestamp
      if [log][timestamp] {
        date {
          match => [ "[log][timestamp]", "ISO8601" ]
          target => "@timestamp"
        }
      }

      # Move any extra fields to a metadata object or keep them accessible
      # We remove the original 'message' and 'log' to keep the document clean
      mutate {
        remove_field => [ "message", "log" ]
      }
    }
  }

  # Add processing metadata
  mutate {
    add_tag => [ "gradeloop_structured" ]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "gradeloop-logs-%{+YYYY.MM.dd}"
    # Using data streams or indices depending on ES version,
    # but index pattern is standard for dev.
  }

  # Useful for debugging log flows during development
  # stdout {
  #   codec => rubydebug
  # }
}
